# ğŸš€ Quick Start Guide - ProjetELK

## DÃ©marrage rapide

### 1. Lancer la stack complÃ¨te
```bash
docker compose up -d
```

### 2. VÃ©rifier que tout fonctionne
```bash
# Elasticsearch
curl http://localhost:9200/_cluster/health

# Kibana
curl http://localhost:5601/api/status

# WebApp
curl http://localhost:8000/

# MongoDB (via Mongo Express)
# Ouvrir http://localhost:8081 dans le navigateur
# Login: meadmin / mechangeme
```

### 3. Uploader un fichier de logs

**Via l'interface web:**
- Ouvrir http://localhost:8000/upload
- Glisser-dÃ©poser un fichier CSV ou JSON
- Voir l'aperÃ§u et confirmer

**Via curl:**
```bash
# CrÃ©er un fichier CSV de test
cat > test.csv << 'CSV'
timestamp,level,message,user
2025-11-25 14:00:00,INFO,User login,alice
2025-11-25 14:00:05,ERROR,Connection failed,bob
2025-11-25 14:00:10,WARNING,High CPU usage,system
CSV

# Uploader
curl -X POST -F "file=@test.csv" http://localhost:8000/upload
```

### 4. VÃ©rifier l'ingestion dans Elasticsearch
```bash
# Attendre 10 secondes que Logstash traite le fichier
sleep 10

# Lister les indices
curl "http://localhost:9200/_cat/indices?v" | grep logstash

# Compter les documents
curl "http://localhost:9200/logstash-csv-*/_count?pretty"

# Rechercher les logs ERROR
curl "http://localhost:9200/logstash-csv-*/_search?pretty&size=5&q=level:ERROR"
```

### 5. Visualiser dans Kibana
1. Ouvrir http://localhost:5601
2. Menu â†’ Stack Management â†’ Index Patterns
3. CrÃ©er pattern: `logstash-csv-*`
4. Choisir `@timestamp` comme champ de temps
5. Menu â†’ Discover â†’ SÃ©lectionner le pattern
6. Explorer les logs!

## ğŸ“ Formats de fichiers supportÃ©s

### CSV
```csv
timestamp,level,message,user
2025-11-25 12:00:00,INFO,Application started,admin
2025-11-25 12:00:05,ERROR,Connection timeout,service
```

### JSON Lines (une ligne = un objet JSON)
```json
{"timestamp":"2025-11-25T12:00:00Z","level":"info","message":"Service started"}
{"timestamp":"2025-11-25T12:00:05Z","level":"error","message":"Database error"}
```

## ğŸ”§ Commandes utiles

### Docker
```bash
# Voir les logs en temps rÃ©el
docker compose logs -f logstash

# RedÃ©marrer un service
docker compose restart webapp

# ArrÃªter la stack
docker compose down

# ArrÃªter et supprimer les volumes
docker compose down -v
```

### Logstash
```bash
# Forcer le retraitement des fichiers
docker compose exec logstash rm -f /usr/share/logstash/data/sincedb_*
docker compose restart logstash

# VÃ©rifier les pipelines actifs
docker compose logs logstash | grep "Pipeline started"
```

### MongoDB
```bash
# AccÃ©der au shell MongoDB
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin

# Voir les fichiers uploadÃ©s
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin --eval "db.getSiblingDB('logsdb').files.find().pretty()"
```

### Elasticsearch
```bash
# SantÃ© du cluster
curl http://localhost:9200/_cluster/health?pretty

# Lister tous les indices
curl http://localhost:9200/_cat/indices?v

# Supprimer un index
curl -X DELETE http://localhost:9200/logstash-csv-2025.11.25
```

## ğŸ› DÃ©pannage

### Logstash ne traite pas les fichiers
1. VÃ©rifier que les fichiers sont dans `/data/uploads/`:
   ```bash
   docker compose exec logstash ls -lh /data/uploads/
   ```

2. VÃ©rifier les logs Logstash:
   ```bash
   docker compose logs --tail=100 logstash | grep -i error
   ```

3. Forcer le retraitement:
   ```bash
   docker compose exec logstash rm -f /usr/share/logstash/data/sincedb_*
   docker compose restart logstash
   ```

### MongoDB connection refused
1. VÃ©rifier que MongoDB est dÃ©marrÃ©:
   ```bash
   docker compose ps mongodb
   ```

2. VÃ©rifier les credentials dans `.env`:
   ```bash
   cat .env | grep MONGO
   ```

### Elasticsearch cluster red/yellow
1. VÃ©rifier les logs:
   ```bash
   docker compose logs elasticsearch | tail -50
   ```

2. Mode single-node est normal en yellow (pas de rÃ©plicas)

## ğŸ“š Documentation complÃ¨te
Voir `README.md` pour la documentation complÃ¨te.

---
**Projet ELK Stack - Monitoring de Logs**
