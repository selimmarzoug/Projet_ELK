# ğŸ” Elasticsearch & Kibana - Exemples de RequÃªtes

## RequÃªtes Elasticsearch via cURL

### 1. Recherche basique

```bash
# Tous les logs ERROR
curl "http://localhost:9200/logstash-*/_search?pretty&q=level:ERROR"

# Recherche full-text dans message
curl "http://localhost:9200/logstash-*/_search?pretty&q=message:connection"

# Par service spÃ©cifique
curl "http://localhost:9200/logstash-*/_search?pretty&q=service:database-service"
```

### 2. Recherche par range d'IP

```bash
# IPs dans le range 192.168.x.x
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "range": {
      "ip": {
        "gte": "192.168.0.0",
        "lte": "192.168.255.255"
      }
    }
  }
}'

# IPs dans le rÃ©seau 10.0.0.0/24
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "term": {
      "ip": "10.0.0.0/24"
    }
  }
}'
```

### 3. Recherche multi-critÃ¨res (bool query)

```bash
# ERROR des derniÃ¨res 24h contenant "timeout"
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "bool": {
      "must": [
        { "term": { "level": "ERROR" }},
        { "match": { "message": "timeout" }},
        { "range": { "@timestamp": { "gte": "now-24h" }}}
      ]
    }
  }
}'

# Logs d'un service spÃ©cifique, excluant INFO
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "bool": {
      "must": [
        { "term": { "service": "database-service" }}
      ],
      "must_not": [
        { "term": { "level": "INFO" }}
      ]
    }
  }
}'
```

### 4. AgrÃ©gations

```bash
# Compter logs par service
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "services": {
      "terms": {
        "field": "service",
        "size": 10
      }
    }
  }
}'

# Compter logs par niveau
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "levels": {
      "terms": {
        "field": "level"
      }
    }
  }
}'

# Histogram par heure
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "logs_over_time": {
      "date_histogram": {
        "field": "@timestamp",
        "fixed_interval": "1h"
      }
    }
  }
}'

# Top utilisateurs
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "top_users": {
      "terms": {
        "field": "user",
        "size": 5
      }
    }
  }
}'
```

### 5. Statistiques

```bash
# Stats sur nombre de logs par service
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "services": {
      "terms": {
        "field": "service"
      },
      "aggs": {
        "levels": {
          "terms": {
            "field": "level"
          }
        }
      }
    }
  }
}'
```

## Configuration Kibana

### 1. CrÃ©er un Index Pattern

1. Ouvrir Kibana: http://localhost:5601
2. Menu â†’ **Stack Management** â†’ **Index Patterns**
3. Cliquer **Create index pattern**
4. Pattern: `logstash-*`
5. Time field: `@timestamp`
6. Cliquer **Create index pattern**

### 2. Discover - RequÃªtes KQL

```
# Recherche basique
level: ERROR

# Recherche avec wildcard
message: *timeout*

# ET logique
level: ERROR AND service: database-service

# OU logique
level: ERROR OR level: WARNING

# NÃ©gation
NOT level: INFO

# Range de dates
@timestamp >= "2025-11-25T00:00:00" AND @timestamp <= "2025-11-25T23:59:59"

# Recherche dans IP
ip: 192.168.*

# Combinaison complexe
(level: ERROR OR level: WARNING) AND service: *-service AND NOT user: system
```

### 3. Visualisations suggÃ©rÃ©es

#### Pie Chart - RÃ©partition par niveau
- **Metrics**: Count
- **Buckets**: Split slices â†’ Terms â†’ Field: `level`

#### Vertical Bar - Logs par service
- **Y-axis**: Count
- **X-axis**: Terms â†’ Field: `service`

#### Line Chart - Timeline des logs
- **Y-axis**: Count
- **X-axis**: Date Histogram â†’ Field: `@timestamp` â†’ Interval: Auto

#### Data Table - Top utilisateurs
- **Metrics**: Count
- **Buckets**: Split rows â†’ Terms â†’ Field: `user` â†’ Size: 10

#### Tag Cloud - Services
- **Tags**: Terms â†’ Field: `service`

#### Heat Map - Services x Niveaux
- **Y-axis**: Terms â†’ Field: `service`
- **X-axis**: Terms â†’ Field: `level`
- **Dot size**: Count

### 4. Dashboard Example

CrÃ©er un dashboard avec:
1. **Metric**: Total de logs (Count)
2. **Metric**: Nombre d'erreurs (Filter: level:ERROR)
3. **Pie**: RÃ©partition par niveau
4. **Bar**: Top 10 services
5. **Line**: Timeline des derniÃ¨res 24h
6. **Table**: Derniers logs ERROR

### 5. Filtres Kibana

Ajoutez des filtres permanents:
- **Field**: `level` â†’ **Operator**: `is` â†’ **Value**: `ERROR`
- **Field**: `@timestamp` â†’ **Operator**: `is between` â†’ Last 7 days
- **Field**: `service` â†’ **Operator**: `is one of` â†’ database-service, api-service

## Alertes (Kibana Alerting)

### CrÃ©er une alerte sur logs ERROR

1. Menu â†’ **Stack Management** â†’ **Rules and Connectors**
2. **Create rule**
3. **Index threshold**:
   - Index: `logstash-*`
   - Threshold: Count > 10
   - Time window: Last 5 minutes
   - Group by: `service`
   - Filter: `level:ERROR`
4. Configurer notification (email, webhook, etc.)

## Scripts utiles

```bash
# Compter les logs par jour
for date in $(seq 20 25); do
  count=$(curl -s "http://localhost:9200/logstash-csv-2025.11.$date/_count" | grep -o '"count":[0-9]*' | cut -d: -f2)
  echo "2025-11-$date: $count logs"
done

# Exporter les logs ERROR en JSON
curl -s "http://localhost:9200/logstash-*/_search?q=level:ERROR&size=100" > errors.json

# Supprimer les vieux indices (>30 jours)
curl -X DELETE "http://localhost:9200/logstash-*-2025.10.*"
```

## Optimisation des requÃªtes

1. **Utiliser des filtres** (term, range) plutÃ´t que des queries (match) quand possible
2. **Limiter la taille** avec `size` parameter
3. **DÃ©sactiver _source** si seuls les agrÃ©gations comptent: `"_source": false`
4. **Utiliser des filtres cached**: Les term queries sont automatiquement cachÃ©es
5. **Index pattern spÃ©cifique**: `logstash-csv-2025.11.25` vs `logstash-*`

---
ğŸ“Š **Explorez vos logs avec puissance!**
