# ProjetELK - Stack Monitoring & WebApp Flask avec Authentification

## ğŸ“š Description
Stack de monitoring de logs basÃ©e sur **Elasticsearch / Logstash / Kibana (ELK)** complÃ©tÃ©e par **MongoDB**, **Redis** et une application **Flask** sÃ©curisÃ©e avec systÃ¨me d'authentification complet.

## ğŸ” SystÃ¨me d'Authentification
L'application est protÃ©gÃ©e par un systÃ¨me d'authentification complet :
- âœ… **Inscription** : CrÃ©ation de compte avec validation
- âœ… **Connexion** : Authentification sÃ©curisÃ©e
- âœ… **Sessions** : Gestion des sessions utilisateur (7 jours)
- âœ… **Mots de passe hashÃ©s** : SÃ©curitÃ© via Werkzeug
- âœ… **Protection des routes** : Toutes les pages nÃ©cessitent une connexion
- âœ… **Stockage MongoDB** : Collection `users` dans `logsdb`

### PremiÃ¨re utilisation
1. AccÃ©dez Ã  http://localhost:8000
2. Vous serez redirigÃ© vers la page de connexion
3. Cliquez sur "CrÃ©er un compte" pour l'inscription
4. Remplissez le formulaire (username min 3 car., password min 6 car.)
5. Vous Ãªtes automatiquement connectÃ© aprÃ¨s inscription

## ğŸ§± Services (docker-compose)
| Service | Port Host | Image | Persistance | Notes |
|---------|-----------|-------|-------------|-------|
| Elasticsearch | 9200 | elasticsearch:8.11.3 | Volume `elasticsearch_data` | Mode single-node, sÃ©curitÃ© dÃ©sactivÃ©e |
| Kibana | 5601 | kibana:8.11.3 | - | Se connecte Ã  Elasticsearch sans credentials |
| Logstash | 5044 / 9600 | logstash:8.11.3 | Volume `logstash_data` + pipeline mount | Pipeline dans `./pipeline/logstash.conf` |
| MongoDB | 27017 | mongo:7.0 | Volumes `mongodb_data`, `mongodb_config` | Auth root via variables .env |
| Redis | 6379 | redis:7.2-alpine | Volume `redis_data` | Mot de passe via .env |
| WebApp Flask | 8000 | build local | Montage code `./webapp` | Application Flask avec authentification |
| Mongo Express | 8081 | mongo-express:1.0.2-18 | - | UI web MongoDB (basic auth via .env) |

## ğŸŒ Endpoints principaux

### Pages Web (nÃ©cessitent authentification)
- **Accueil / Dashboard** : http://localhost:8000/
- **Connexion** : http://localhost:8000/login
- **Inscription** : http://localhost:8000/register
- **Upload Interface** : http://localhost:8000/upload
- **Recherche** : http://localhost:8000/search
- **Health Dashboard** : http://localhost:8000/health-dashboard â­ NOUVEAU

### API & Services
- **API Health Check** : http://localhost:8000/health (public)
- **Elasticsearch** : http://localhost:9200/
- **Kibana** : http://localhost:5601/
- **MongoDB** : mongodb://admin:changeme@localhost:27017/
- **Redis** : redis://:changeme@localhost:6379
- **Mongo Express (UI)** : http://localhost:8081/

## ğŸ¯ FonctionnalitÃ©s principales

### ğŸ”‘ Authentification & SÃ©curitÃ©
- Pages de login/register avec design moderne
- Validation des formulaires cÃ´tÃ© serveur
- Messages flash pour feedback utilisateur
- Protection de toutes les routes sensibles
- Menu utilisateur avec nom et dÃ©connexion

### ğŸ“Š Dashboard Principal
- **Total Logs** : Nombre de documents indexÃ©s
- **Logs Aujourd'hui** : EntrÃ©es du jour
- **Erreurs** : Logs en erreur (status: failed)
- **Fichiers UploadÃ©s** : CSV & JSON traitÃ©s
- **Graphique Timeline** : Ã‰volution des logs sur 24h

### ğŸ’š Health Dashboard (Nouveau!)
Design moderne avec :
- **Statut global** : Healthy / Degraded / Unhealthy
- **Cartes des services** : Elasticsearch, MongoDB, Redis
- **MÃ©triques en temps rÃ©el** : Services actifs, heure systÃ¨me
- **Auto-refresh** : Mise Ã  jour automatique toutes les 30s
- **Design Ã©lÃ©gant** : Animations, gradients, effets hover

### ğŸ“¤ Module d'Upload de Fichiers

### Interface Web
AccÃ©dez Ã  http://localhost:8000/upload pour uploader des fichiers CSV ou JSON.

**FonctionnalitÃ©s :**
- âœ… Drag & drop ou sÃ©lection de fichier
- âœ… Validation des extensions (.csv, .json)
- âœ… Barre de progression d'upload
- âœ… AperÃ§u des 10 premiÃ¨res lignes
- âœ… Stockage des mÃ©tadonnÃ©es dans MongoDB
- âœ… Ingestion automatique par Logstash

### Upload via API (curl)
```bash
# Upload un fichier CSV
curl -X POST -F "file=@test_logs.csv" http://localhost:8000/upload

# Upload un fichier JSON
curl -X POST -F "file=@test_logs.json" http://localhost:8000/upload
```

**RÃ©ponse JSON :**
```json
{
  "success": true,
  "file_id": "69258f89087369731aad7241",
  "filename": "test2.csv",
  "type": "csv",
  "size": 187,
  "upload_date": "2025-11-25T11:14:17.126729",
  "mongodb_stored": true,
  "headers": ["timestamp", "level", "message", "user"],
  "preview": [
    ["2025-11-25 12:00:00", "INFO", "Application started", "admin"],
    ["2025-11-25 12:00:05", "DEBUG", "Configuration loaded", "system"]
  ]
}
```

### Stockage
- **Fichiers**: Volume Docker `uploads_data` montÃ© sur `/data/uploads/`
- **MÃ©tadonnÃ©es**: Collection MongoDB `files` dans la base `logsdb`

**SchÃ©ma MongoDB :**
```javascript
{
  "_id": ObjectId("69258f89087369731aad7241"),
  "filename": "test2.csv",
  "original_filename": "test2.csv",
  "size": 187,
  "type": "csv",
  "upload_date": ISODate("2025-11-25T11:14:17.126Z"),
  "filepath": "/data/uploads/test2.csv",
  "status": "uploaded"
}
```

### VÃ©rifier les uploads
```bash
# Lister les fichiers uploadÃ©s
docker compose exec webapp ls -lh /data/uploads/

# Voir les mÃ©tadonnÃ©es dans MongoDB
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin --eval "db.getSiblingDB('logsdb').files.find().pretty()"
```

## ğŸ”Œ Healthchecks
- Elasticsearch: `_cluster/health`
- Webapp: `/` (HTTP 200)
- Kibana: `/api/status`
- MongoDB / Redis: healthcheck interne Docker

## ğŸ“‚ Structure clÃ©
```
ProjetELK/
  docker-compose.yml
  Dockerfile
  requirements.txt
  .env / .env.example
  webapp/
    app.py
    routes/
    models/
    utils/
    templates/
    static/
  pipeline/
    logstash.conf
```

## ğŸ›  Logstash Multi-Pipeline Configuration

### Architecture
Le projet utilise une **configuration multi-pipeline** pour traiter simultanÃ©ment diffÃ©rents types de fichiers :
- **CSV Pipeline** (`csv-logs`) : Ingestion de fichiers CSV avec parsing automatique
- **JSON Pipeline** (`json-logs`) : Ingestion de fichiers JSON Lines

Configuration dÃ©finie dans `pipeline/pipelines.yml` :
```yaml
- pipeline.id: csv-logs
  path.config: "/usr/share/logstash/pipeline/csv-pipeline.conf"
  pipeline.workers: 1
  pipeline.batch.size: 125

- pipeline.id: json-logs
  path.config: "/usr/share/logstash/pipeline/json-pipeline.conf"
  pipeline.workers: 1
  pipeline.batch.size: 125
```

### CSV Pipeline (`pipeline/csv-pipeline.conf`)
âœ… **Fonctionnel et testÃ©**

```conf
input {
  file {
    path => "/data/uploads/*.csv"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_csv"
    mode => "read"
    file_completed_action => "log"
    file_completed_log_path => "/usr/share/logstash/data/completed_csv.log"
    codec => plain
  }
}

filter {
  csv {
    separator => ","
    autodetect_column_names => true
    autogenerate_column_names => true
  }
  
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "yyyy-MM-dd'T'HH:mm:ss'Z'", "yyyy-MM-dd'T'HH:mm:ssZ"]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }
  }
  
  mutate {
    add_field => {
      "source_type" => "csv"
      "source_file" => "%{[log][file][path]}"
      "ingestion_timestamp" => "%{@timestamp}"
    }
  }
  
  if [level] {
    mutate { uppercase => ["level"] }
  }
  
  mutate {
    remove_field => ["host", "event"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logstash-csv-%{+YYYY.MM.dd}"
    data_stream => false
  }
  
  stdout {
    codec => rubydebug { metadata => true }
  }
}
```

**Format CSV attendu :**
```csv
timestamp,level,message,user
2025-11-25 12:00:00,INFO,Application started,admin
2025-11-25 12:00:05,DEBUG,Configuration loaded,system
2025-11-25 12:00:10,ERROR,Connection timeout,service
```

### JSON Pipeline (`pipeline/json-pipeline.conf`)
âš ï¸ **NÃ©cessite format JSON Lines** (une ligne JSON par Ã©vÃ©nement)

```conf
input {
  file {
    path => "/data/uploads/*.json"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/data/sincedb_json"
    mode => "read"
    file_completed_action => "log"
    file_completed_log_path => "/usr/share/logstash/data/completed_json.log"
    codec => "json_lines"
  }
}

filter {
  json {
    source => "message"
    target => "parsed_json"
    skip_on_invalid_json => true
  }
  
  ruby {
    code => "
      parsed = event.get('parsed_json')
      if parsed.is_a?(Hash)
        parsed.each { |k, v| event.set(k, v) }
      end
    "
  }
  
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601", "yyyy-MM-dd'T'HH:mm:ss'Z'", "yyyy-MM-dd'T'HH:mm:ssZ", "yyyy-MM-dd HH:mm:ss"]
      target => "@timestamp"
      remove_field => ["timestamp"]
    }
  }
  
  mutate {
    add_field => {
      "source_type" => "json"
      "source_file" => "%{[log][file][path]}"
      "ingestion_timestamp" => "%{@timestamp}"
    }
  }
  
  if [level] {
    mutate { uppercase => ["level"] }
  }
  
  if [message] and [message] =~ /ERROR|WARN|INFO|DEBUG/ {
    grok {
      match => {
        "message" => [
          "%{LOGLEVEL:extracted_level}",
          ".*%{LOGLEVEL:extracted_level}.*"
        ]
      }
      pattern_definitions => {
        "LOGLEVEL" => "(ERROR|WARN|WARNING|INFO|DEBUG|TRACE|FATAL)"
      }
      tag_on_failure => []
    }
  }
  
  mutate {
    remove_field => ["host", "event"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "logstash-json-%{+YYYY.MM.dd}"
    data_stream => false
  }
  
  stdout {
    codec => rubydebug { metadata => true }
  }
}
```

**Format JSON Lines attendu :**
```json
{"timestamp":"2025-11-25T12:10:00Z","level":"info","message":"Service started","service":"api"}
{"timestamp":"2025-11-25T12:10:05Z","level":"error","message":"Database ERROR occurred","service":"db"}
{"timestamp":"2025-11-25T12:10:10Z","level":"warning","message":"High memory WARNING detected","service":"monitor"}
```

### ğŸ“Š VÃ©rifier l'ingestion

**Lister les indices :**
```bash
curl -s http://localhost:9200/_cat/indices?v | grep logstash
```

**Compter les documents CSV :**
```bash
curl -s "http://localhost:9200/logstash-csv-*/_count?pretty"
```

**Rechercher dans les logs CSV :**
```bash
curl -s -X GET "http://localhost:9200/logstash-csv-*/_search?pretty&size=5&q=level:ERROR"
```

**Exemple de document indexÃ© :**
```json
{
  "_index": "logstash-csv-2025.11.25",
  "_id": "kFi4upoBo8sA3KWOsjoZ",
  "_source": {
    "user": "admin",
    "@version": "1",
    "log": {
      "file": {
        "path": "/data/uploads/test2.csv"
      }
    },
    "source_type": "csv",
    "ingestion_timestamp": "2025-11-25T12:00:00.000Z",
    "@timestamp": "2025-11-25T12:00:00.000Z",
    "message": "Application started",
    "source_file": "/data/uploads/test2.csv",
    "level": "INFO"
  }
}
```

### ğŸ” Debugging Logstash

**Voir les logs en temps rÃ©el :**
```bash
docker compose logs -f logstash
```

**VÃ©rifier que les pipelines sont dÃ©marrÃ©s :**
```bash
docker compose logs logstash | grep "Pipeline started"
```

**VÃ©rifier le sincedb (fichiers traitÃ©s) :**
```bash
docker compose exec logstash cat /usr/share/logstash/data/sincedb_csv
docker compose exec logstash cat /usr/share/logstash/data/sincedb_json
```

**Forcer le retraitement des fichiers :**
```bash
docker compose exec logstash rm -f /usr/share/logstash/data/sincedb_*
docker compose restart logstash
```

## ï¿½ Index Template Elasticsearch

### Template `logs-template`
Un index template est configurÃ© pour tous les indices `logstash-*` avec des mappings optimisÃ©s :

```json
{
  "index_patterns": ["logstash-*"],
  "priority": 200,
  "template": {
    "settings": {
      "number_of_shards": 1,
      "number_of_replicas": 0,
      "index.refresh_interval": "5s"
    },
    "mappings": {
      "properties": {
        "timestamp": { "type": "date" },
        "@timestamp": { "type": "date" },
        "level": { "type": "keyword" },
        "message": { 
          "type": "text",
          "fields": {
            "keyword": { "type": "keyword" }
          }
        },
        "service": { "type": "keyword" },
        "ip": { "type": "ip" },
        "ip_address": { "type": "ip" },
        "user": { "type": "keyword" },
        "source_type": { "type": "keyword" },
        "source_file": { "type": "keyword" }
      }
    }
  }
}
```

**Fichier**: `logs-template.json`

### CrÃ©er/Mettre Ã  jour le template
```bash
curl -X PUT "http://localhost:9200/_index_template/logs-template" \
  -H 'Content-Type: application/json' \
  -d @logs-template.json
```

### VÃ©rifier le template
```bash
# Lister tous les templates
curl "http://localhost:9200/_index_template?pretty"

# Voir un template spÃ©cifique
curl "http://localhost:9200/_index_template/logs-template?pretty"
```

### VÃ©rifier qu'un index utilise le template
```bash
# Voir le mapping d'un index
curl "http://localhost:9200/logstash-csv-2025.11.25/_mapping?pretty"
```

### Types de champs configurÃ©s

| Champ | Type | Description | Exemple de requÃªte |
|-------|------|-------------|-------------------|
| `timestamp` / `@timestamp` | `date` | Date du log | Recherche par plage de dates |
| `level` | `keyword` | Niveau de log (INFO, ERROR, etc.) | Filtrage exact : `level:ERROR` |
| `message` | `text` + `keyword` | Message du log, analysÃ© pour recherche full-text | Recherche texte : `message:authentication` |
| `service` | `keyword` | Nom du service | AgrÃ©gation par service |
| `ip` / `ip_address` | `ip` | Adresse IP | Range : `ip:[192.168.0.0 TO 192.168.255.255]` |
| `user` | `keyword` | Utilisateur | Filtrage : `user:alice` |

### Exemples de requÃªtes avancÃ©es

**Recherche par range IP (CIDR) :**
```bash
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "range": {
      "ip": {
        "gte": "192.168.0.0",
        "lte": "192.168.255.255"
      }
    }
  }
}'
```

**AgrÃ©gation par service :**
```bash
curl -X GET "http://localhost:9200/logstash-*/_search?pretty&size=0" -H 'Content-Type: application/json' -d'
{
  "aggs": {
    "services": {
      "terms": {
        "field": "service",
        "size": 10
      }
    }
  }
}'
```

**Filtrage multi-critÃ¨res :**
```bash
curl -X GET "http://localhost:9200/logstash-*/_search?pretty" -H 'Content-Type: application/json' -d'
{
  "query": {
    "bool": {
      "must": [
        { "match": { "message": "error" }},
        { "term": { "level": "ERROR" }},
        { "range": { "@timestamp": { "gte": "now-1h" }}}
      ]
    }
  }
}'
```

## ï¿½ğŸš€ DÃ©marrage
```bash
# Construire l'image webapp
docker compose build webapp

# Lancer toute la stack
docker compose up -d

# VÃ©rifier Ã©tat
curl -s http://localhost:9200/_cluster/health
curl -s -o /dev/null -w '%{http_code}\n' http://localhost:5601/api/status
curl -s http://localhost:8000/
```

### Lancer seulement MongoDB ou Mongo Express
```bash
# Lancer MongoDB seul
docker compose up -d mongodb

# Lancer Mongo Express (UI) seul
docker compose up -d mongo-express
```

## ğŸ§ª DÃ©veloppement local (sans Docker)
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
python webapp/app.py
```

## ğŸ” Variables (.env)
```
ELASTIC_USERNAME=elastic (non utilisÃ© quand sÃ©curitÃ© off)
ELASTIC_PASSWORD=changeme (supprimÃ© cÃ´tÃ© compose)
MONGO_ROOT_USERNAME=admin
MONGO_ROOT_PASSWORD=changeme
MONGO_DATABASE=logsdb
REDIS_PASSWORD=changeme
FLASK_ENV=development
MONGO_EXPRESS_USERNAME=meadmin
MONGO_EXPRESS_PASSWORD=mechangeme
```
Adapter les mots de passe avant production.

## ğŸ—„ï¸ MongoDB: connexions rapides

Depuis l'hÃ´te (si `mongosh` installÃ©) :
```bash
mongosh "mongodb://admin:changeme@localhost:27017/logsdb?authSource=admin"
```

Depuis le conteneur (pas besoin d'installer `mongosh` en local) :
```bash
docker compose exec mongodb mongosh -u "$MONGO_ROOT_USERNAME" -p "$MONGO_ROOT_PASSWORD" --authenticationDatabase admin
```

CrÃ©er un utilisateur applicatif (optionnel) :
```javascript
use logsdb
db.createUser({ user: "appuser", pwd: "app_pass_123", roles: [{ role: "readWrite", db: "logsdb" }] })
```

Connexion ensuite :
```bash
mongosh "mongodb://appuser:app_pass_123@localhost:27017/logsdb"
```

## ğŸ–¥ï¸ Mongo Express (UI)

- URL: http://localhost:8081
- Identifiants (par dÃ©faut):
  - Utilisateur: `meadmin`
  - Mot de passe: `mechangeme`

Changer les identifiants dans `.env`, puis :
```bash
docker compose up -d --force-recreate mongo-express
```

## âœ… Actions dÃ©jÃ  rÃ©alisÃ©es

### Infrastructure
- âœ… Docker-compose avec 7 services (Elasticsearch, Kibana, Logstash, MongoDB, Redis, Flask WebApp, Mongo Express)
- âœ… Volumes persistants pour toutes les donnÃ©es
- âœ… Network bridge `elk_net` pour communication inter-services
- âœ… Politique de restart `unless-stopped` pour dÃ©marrage automatique au boot
- âœ… Healthchecks pour Elasticsearch, Kibana, MongoDB, WebApp

### Configuration Logstash
- âœ… Multi-pipeline avec `pipelines.yml`
- âœ… CSV Pipeline fonctionnel (csv-pipeline.conf) avec parsing automatique
- âœ… JSON Pipeline configurÃ© (json-pipeline.conf) pour JSON Lines
- âœ… Volume `/data/uploads` montÃ© en lecture seule
- âœ… Sincedb tracking pour Ã©viter les doublons
- âœ… Output vers Elasticsearch avec indices datÃ©s

### Application Flask
- âœ… Interface d'upload avec drag & drop
- âœ… Validation des fichiers (CSV/JSON uniquement)
- âœ… Preview des 10 premiÃ¨res lignes
- âœ… Stockage des mÃ©tadonnÃ©es dans MongoDB
- âœ… API REST pour upload programmatique
- âœ… Connexion MongoDB avec authentification
- âœ… Barre de progression d'upload

### Tests & Validation
- âœ… Upload CSV testÃ© avec succÃ¨s (3 documents indexÃ©s)
- âœ… VÃ©rification de l'indexation dans Elasticsearch
- âœ… VÃ©rification des mÃ©tadonnÃ©es dans MongoDB
- âœ… Parsing des timestamps et normalisation des niveaux de log

### RÃ©solutions de problÃ¨mes
- âœ… Correction erreur Kibana (username superuser interdit avec security disabled)
- âœ… Fix permission Logstash `file_completed_log_path`
- âœ… Correction index Elasticsearch (data_stream conflict)
- âœ… Fix interpolation des champs ECS (log.file.path)
- âœ… Nettoyage des credentials inutiles
## ğŸ“Š Collections MongoDB

### `users` (SystÃ¨me d'authentification)
```javascript
{
  "_id": ObjectId("..."),
  "username": "admin",
  "email": "admin@example.com",
  "password_hash": "$pbkdf2-sha256$...",
  "created_at": ISODate("2026-01-02T15:00:00.000Z")
}
```

### `files` (MÃ©tadonnÃ©es des uploads)
```javascript
{
  "_id": ObjectId("69258f89087369731aad7241"),
  "filename": "test2.csv",
  "original_filename": "test2.csv",
  "size": 187,
  "type": "csv",
  "upload_date": ISODate("2025-11-25T11:14:17.126Z"),
  "filepath": "/data/uploads/test2.csv",
  "status": "uploaded"
}
```

### `search_history` (Historique des recherches)
Stocke l'historique des requÃªtes de recherche avec timestamp.

## ğŸš€ DÃ©marrage Rapide

### 1. Lancer la stack complÃ¨te
```bash
docker compose up -d
```

### 2. VÃ©rifier que tout fonctionne
```bash
# Voir l'Ã©tat des conteneurs
docker compose ps

# Tester Elasticsearch
curl http://localhost:9200/_cluster/health

# Tester l'API Health
curl http://localhost:9200/health | jq
```

### 3. CrÃ©er un compte utilisateur
1. Ouvrez http://localhost:8000
2. Vous serez redirigÃ© vers `/login`
3. Cliquez sur "CrÃ©er un compte"
4. Remplissez :
   - Username : `admin` (min 3 caractÃ¨res)
   - Email : `admin@example.com`
   - Password : `admin123` (min 6 caractÃ¨res)
5. Vous Ãªtes automatiquement connectÃ© !

### 4. Explorer l'application
- **Dashboard** : Statistiques et graphiques
- **Upload** : Envoyer des fichiers CSV/JSON
- **Search** : Rechercher dans les logs
- **Health** : Monitoring des services

### 5. Uploader un fichier de test
Le fichier `test_today_2026.csv` contient 30 transactions du jour :
```bash
curl -X POST -F "file=@test_today_2026.csv" \
  http://localhost:8000/upload
```

Ou via l'interface : http://localhost:8000/upload

### 6. AccÃ©der Ã  Kibana
1. Ouvrez http://localhost:5601
2. CrÃ©ez un Data View : `logstash-csv-*` avec `@timestamp`
3. Explorez vos donnÃ©es dans Discover

## ğŸ”§ Structure du Projet

```
ProjetELK/
â”œâ”€â”€ docker-compose.yml              # Configuration des services
â”œâ”€â”€ Dockerfile                      # Image webapp Flask
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python
â”œâ”€â”€ README.md                       # Cette documentation
â”œâ”€â”€ test_today_2026.csv            # Fichier de test avec dates rÃ©centes
â”‚
â”œâ”€â”€ pipeline/                       # Configuration Logstash
â”‚   â”œâ”€â”€ pipelines.yml              # Multi-pipeline config
â”‚   â”œâ”€â”€ csv-pipeline.conf          # Pipeline CSV
â”‚   â””â”€â”€ json-pipeline.conf         # Pipeline JSON
â”‚
â””â”€â”€ webapp/                         # Application Flask
    â”œâ”€â”€ app.py                     # Application principale
    â”œâ”€â”€ database.py                # Gestion MongoDB/Redis
    â”‚
    â”œâ”€â”€ models/                    # ModÃ¨les de donnÃ©es
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ user.py               # ModÃ¨le User + UserManager
    â”‚
    â”œâ”€â”€ routes/                    # Routes Blueprint
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ auth.py               # Routes authentification
    â”‚
    â”œâ”€â”€ templates/                 # Templates Jinja2
    â”‚   â”œâ”€â”€ base.html             # Template de base
    â”‚   â”œâ”€â”€ index.html            # Dashboard principal
    â”‚   â”œâ”€â”€ login.html            # Page de connexion
    â”‚   â”œâ”€â”€ register.html         # Page d'inscription
    â”‚   â”œâ”€â”€ upload.html           # Page d'upload
    â”‚   â”œâ”€â”€ search.html           # Page de recherche
    â”‚   â””â”€â”€ health_dashboard.html # Health monitoring
    â”‚
    â”œâ”€â”€ static/                    # Fichiers statiques
    â””â”€â”€ uploads/                   # Fichiers uploadÃ©s
```
## ï¿½ Prompt 8 â€” Configuration Kibana Dashboard E-Commerce

### Fichiers crÃ©Ã©s
- âœ… **ecommerce_transactions.csv** : 100 transactions e-commerce avec timestamps, montants, types de paiement, statuts (success/failed)
- âœ… **KIBANA_SETUP_GUIDE.md** : Guide complet pas Ã  pas pour la configuration Kibana
- âœ… **kibana_setup.sh** : Script de vÃ©rification des services et affichage des Ã©tapes
- âœ… **export_kibana_dashboard.sh** : Script automatique d'export du dashboard

### Ã‰tapes de configuration

#### 1. Upload des donnÃ©es
```bash
# Le fichier ecommerce_transactions.csv contient 100 transactions
# Uploadez-le via l'interface web : http://localhost:8000/upload
```

#### 2. CrÃ©er l'index pattern dans Kibana
1. Ouvrez Kibana : http://localhost:5601
2. Menu â˜° â†’ Management â†’ Stack Management â†’ Data Views
3. Create data view :
   - Name: `Logs Pattern`
   - Index pattern: `logstash-*`
   - Timestamp field: `@timestamp`

#### 3. CrÃ©er les 3 visualisations

**Visualisation 1 : Transactions par Heure**
- Type : Area/Line Chart
- Axe Y : Count
- Axe X : Date Histogram (@timestamp, intervalle 1h)
- Nom : `E-Commerce - Transactions par Heure`

**Visualisation 2 : Top 10 des Erreurs**
- Type : Horizontal Bar Chart
- Filtre : status=failed
- Axe Y : Count
- Axe X : Terms (error_message.keyword, top 10)
- Nom : `E-Commerce - Top 10 Erreurs`

**Visualisation 3 : RÃ©partition par Type de Paiement**
- Type : Pie Chart (Donut)
- Slice size : Count
- Split slices : Terms (payment_type.keyword)
- Nom : `E-Commerce - RÃ©partition Paiements`

#### 4. CrÃ©er le dashboard
1. Menu â˜° â†’ Dashboard â†’ Create dashboard
2. Add from library â†’ SÃ©lectionner les 3 visualisations
3. Organiser le layout (transactions en haut, 2 autres en bas)
4. Save : `E-Commerce Logs Dashboard`

#### 5. Exporter le dashboard
```bash
# MÃ©thode 1 : Via l'interface Kibana
# Stack Management â†’ Saved Objects â†’ SÃ©lectionner les objets â†’ Export

# MÃ©thode 2 : Via script automatique
./export_kibana_dashboard.sh
```

### Commandes de vÃ©rification

```bash
# Lancer le script de setup (affiche toutes les infos)
./kibana_setup.sh

# VÃ©rifier les donnÃ©es indexÃ©es
curl -s 'http://localhost:9200/logstash-*/_count' | jq

# Voir les transactions Ã©chouÃ©es
curl -s -X POST 'http://localhost:9200/logstash-*/_search' \
  -H 'Content-Type: application/json' \
  -d '{"query":{"match":{"status":"failed"}},"size":5}' | jq '.hits.hits[]._source'

# AgrÃ©gation par type de paiement
curl -s -X POST 'http://localhost:9200/logstash-*/_search' \
  -H 'Content-Type: application/json' \
  -d '{"size":0,"aggs":{"payment_types":{"terms":{"field":"payment_type.keyword"}}}}' | jq '.aggregations'
```

### Documentation
Pour le guide complet avec captures d'Ã©cran et instructions dÃ©taillÃ©es :
```bash
cat KIBANA_SETUP_GUIDE.md
```

### DonnÃ©es E-Commerce
Le fichier CSV contient :
- **100 transactions** du 25 novembre 2025 (8h00-17h45)
- **Statuts** : 75 success, 25 failed
- **Types de paiement** : credit_card, paypal, debit_card, bank_transfer
- **CatÃ©gories** : Electronics, Clothing, Sports, Food, Home, Beauty, Books
- **Pays** : France, Germany, Italy, Spain, Belgium
- **Erreurs** : Payment declined, Card validation failed, Network timeout, Payment gateway error, Card expired

---

## ï¿½ï¸ Commandes Utiles

### Docker
```bash
# Lancer tous les services
docker compose up -d

# ArrÃªter tous les services
docker compose down

# Voir les logs d'un service
docker compose logs -f webapp
docker compose logs -f logstash
docker compose logs -f elasticsearch

# RedÃ©marrer un service
docker compose restart webapp

# Voir l'Ã©tat des conteneurs
docker compose ps

# Reconstruire l'image webapp
docker compose build webapp

# Nettoyer tout (attention : supprime les volumes)
docker compose down -v
```

### Elasticsearch
```bash
# SantÃ© du cluster
curl http://localhost:9200/_cluster/health | jq

# Lister tous les indices
curl http://localhost:9200/_cat/indices?v

# Compter les documents dans un index
curl "http://localhost:9200/logstash-csv-*/_count" | jq

# Rechercher dans les logs
curl -X POST "http://localhost:9200/logstash-*/_search" \
  -H "Content-Type: application/json" \
  -d '{"query": {"match_all": {}}, "size": 10}' | jq

# Supprimer un index
curl -X DELETE "http://localhost:9200/logstash-csv-2025.11.25"
```

### MongoDB
```bash
# Se connecter au shell MongoDB
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin

# Voir les bases de donnÃ©es
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin \
  --eval "show dbs"

# Voir les utilisateurs
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin \
  --eval "db.getSiblingDB('logsdb').users.find().pretty()"

# Voir les fichiers uploadÃ©s
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin \
  --eval "db.getSiblingDB('logsdb').files.find().pretty()"

# Compter les documents
docker compose exec mongodb mongosh -u admin -p changeme --authenticationDatabase admin \
  --eval "db.getSiblingDB('logsdb').users.countDocuments({})"
```

### Redis
```bash
# Se connecter Ã  Redis CLI
docker compose exec redis redis-cli -a changeme

# Voir toutes les clÃ©s
docker compose exec redis redis-cli -a changeme KEYS "*"

# Obtenir une valeur
docker compose exec redis redis-cli -a changeme GET "ma-cle"

# Info sur Redis
docker compose exec redis redis-cli -a changeme INFO
```

### Webapp Flask
```bash
# AccÃ©der au shell du conteneur
docker compose exec webapp bash

# Voir les fichiers uploadÃ©s
docker compose exec webapp ls -lh /data/uploads/

# Tester la connexion Python
docker compose exec webapp python3 -c "
from database import get_mongodb_db
print('MongoDB:', get_mongodb_db())
"
```

### Tests & Monitoring
```bash
# Tester l'API Health
curl http://localhost:8000/health | jq

# Uploader un fichier via curl
curl -X POST -F "file=@test_today_2026.csv" \
  http://localhost:8000/upload | jq

# Voir les index patterns Kibana
curl -s "http://localhost:5601/api/saved_objects/_find?type=index-pattern" | jq

# VÃ©rifier les pipelines Logstash
curl http://localhost:9600/_node/stats/pipelines?pretty
```

## ğŸ”œ IdÃ©es futures
- âœ… SystÃ¨me d'authentification avec MongoDB
- âœ… Page Health Dashboard avec design moderne
- âœ… Protection des routes sensibles
- âœ… Upload de fichiers avec dates rÃ©centes
- ğŸ”œ RÃ´les utilisateur (admin, user, viewer)
- ğŸ”œ Activer sÃ©curitÃ© Elasticsearch (API Keys / service account)
- ğŸ”œ Ajouter Filebeat ou Metricbeat
- ğŸ”œ Alertes Kibana sur taux d'erreur Ã©levÃ©
- ğŸ”œ Tests automatisÃ©s (PyTest) pour la webapp
- ğŸ”œ IntÃ©gration CI (GitHub Actions)
- ğŸ”œ Export de rapports PDF
- ğŸ”œ Notifications par email

## ğŸ“ Liens utiles
- Elasticsearch Docs: https://www.elastic.co/guide/index.html
- Kibana Docs: https://www.elastic.co/guide/en/kibana/current/index.html
- Logstash Docs: https://www.elastic.co/guide/en/logstash/current/index.html
- Flask: https://flask.palletsprojects.com/
- PyMongo: https://pymongo.readthedocs.io/
- Redis Python: https://redis-py.readthedocs.io/

---

## ğŸ‘¤ Auteur & Contributions
Projet dÃ©veloppÃ© avec assistance IA (2 janvier 2026)

### FonctionnalitÃ©s implÃ©mentÃ©es
- âœ… Stack ELK complÃ¨te avec Docker Compose
- âœ… Application Flask avec interface moderne
- âœ… SystÃ¨me d'authentification sÃ©curisÃ©
- âœ… Upload de fichiers CSV/JSON
- âœ… Dashboard de monitoring avec statistiques
- âœ… Health Dashboard pour surveillance systÃ¨me
- âœ… Recherche avancÃ©e dans les logs
- âœ… IntÃ©gration MongoDB + Redis
- âœ… Multi-pipeline Logstash (CSV + JSON)

---
**Bon monitoring !** ğŸš€ğŸ“ŠğŸ’š
